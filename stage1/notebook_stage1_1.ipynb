{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60d69e87",
   "metadata": {},
   "source": [
    "##### About this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5693c94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------------------------------------------\n",
    "# Author:             Erick Rico Esparza\n",
    "# Dates:              Jan 12 - 20, 2025\n",
    "# Description:        Data sanity check + seasonality consistency prior to full analysis + diurnal cycle exploration\n",
    "# Organization:       Tampere University / Institute of Atmospheric Sciences and Climate Change (ICAyCC-UNAM)\n",
    "#-----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f3f29c",
   "metadata": {},
   "source": [
    "# Stage 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1346d1df",
   "metadata": {},
   "source": [
    "## 1. Setup & constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ef9ff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy.stats import ttest_ind\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from xarray.coding.variables import SerializationWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=SerializationWarning)\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86d0f6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "from scipy.stats import linregress\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f819f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Set display formatting\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f929d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Domain & constants\n",
    "LON_MIN, LON_MAX = -120, -85\n",
    "LAT_MIN, LAT_MAX = 12, 33\n",
    "LON_CDMX, LAT_CDMX = -99.13, 19.43\n",
    "\n",
    "# MCMA box\n",
    "SW_lat, SW_lon = 18.3, -100.9\n",
    "NE_lat, NE_lon = 20.7, -97.4\n",
    "MCMA_BOX = (SW_lon, SW_lat, NE_lon - SW_lon, NE_lat - SW_lat)\n",
    "\n",
    "pollutants = [\"PM2.5\", \"PM10\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b90c624",
   "metadata": {},
   "source": [
    "## 2. Load reanalysis + pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea13421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 500 hPa\n",
    "H500 = xr.open_dataset(\"hgt500_mex_2012_2024.nc\")[\"hgt\"]\n",
    "U500 = xr.open_dataset(\"uwnd500_mex_2012_2024.nc\")[\"uwnd\"]\n",
    "V500 = xr.open_dataset(\"vwnd500_mex_2012_2024.nc\")[\"vwnd\"]\n",
    "\n",
    "# Force datetime format if necessary\n",
    "H500 = H500.assign_coords(time=pd.to_datetime(H500.time.values))\n",
    "U500 = U500.assign_coords(time=pd.to_datetime(U500.time.values))\n",
    "V500 = V500.assign_coords(time=pd.to_datetime(V500.time.values))\n",
    "\n",
    "lon2d, lat2d = H500[\"lon\"].values, H500[\"lat\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655fa0b2",
   "metadata": {},
   "source": [
    "## 3. PM daily + extremos mensuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d600b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event day count (p90 within each month-year):\n",
      "PM2.5 {1: 49, 2: 39, 3: 52, 4: 39, 5: 48, 6: 37, 7: 52, 8: 55, 9: 39, 10: 49, 11: 38, 12: 52}\n",
      "PM10 {1: 49, 2: 38, 3: 52, 4: 40, 5: 48, 6: 37, 7: 51, 8: 51, 9: 37, 10: 49, 11: 39, 12: 51}\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"pm_cdmx_citymean_daily_2012_2024.csv\")\n",
    "df[\"DATE\"] = pd.to_datetime(df[\"DATE\"])\n",
    "df = df.set_index(\"DATE\").sort_index()\n",
    "\n",
    "def p90_events_by_month(series: pd.Series) -> dict:\n",
    "    \"\"\"\n",
    "    Returns dict: month(int 1-12) -> DatetimeIndex of event days (p90 within each month-year)\n",
    "    Similiar to SEE4994's Week 6 logic, but organized by calendar month.\n",
    "    \"\"\"\n",
    "    out = {m: [] for m in range(1, 13)}\n",
    "    for _, s in series.groupby(series.index.to_period(\"M\")):\n",
    "        if len(s) == 0:\n",
    "            continue\n",
    "        thr = s.quantile(0.90)\n",
    "        ev = s[s >= thr].index\n",
    "        m = ev[0].month if len(ev) else None\n",
    "        if m is not None:\n",
    "            out[m].extend(list(ev))\n",
    "    # unique + sort\n",
    "    return {m: pd.DatetimeIndex(sorted(set(out[m]))) for m in out}\n",
    "\n",
    "events_p90 = {p: p90_events_by_month(df[p].dropna()) for p in pollutants}\n",
    "\n",
    "print(\"Event day count (p90 within each month-year):\")\n",
    "for p in pollutants:\n",
    "    counts = {m: len(events_p90[p][m]) for m in range(1, 13)}\n",
    "    print(p, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a03972d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 4555 entries, 2012-01-01 to 2024-12-31\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   PM10    4555 non-null   float64\n",
      " 1   PM2.5   4555 non-null   float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 106.8 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584f0615",
   "metadata": {},
   "source": [
    "## 4. Climatology + anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8975571f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_climatology(da):\n",
    "    da = da.assign_coords(time=pd.to_datetime(da.time.values))\n",
    "    da_noleap = da.sel(time=~((da.time.dt.month==2) & (da.time.dt.day==29)))\n",
    "    clim = da_noleap.groupby(\"time.dayofyear\").mean(\"time\")\n",
    "    clim = clim.rolling(dayofyear=31, center=True, min_periods=1).mean()\n",
    "    return clim\n",
    "\n",
    "clim500 = daily_climatology(H500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130190cc",
   "metadata": {},
   "source": [
    "## 5. Monthly composites + 3×4 multipanel (12 months)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68f8beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute H′ anomalies relative to daily climatology\n",
    "# Using groupby to align daily climatology (dayofyear) with the time dimension\n",
    "Hprime500 = H500.groupby(\"time.dayofyear\") - clim500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e220c57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_22824\\2201075985.py:136: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0, 0.9, 0.95])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: Z500_monthly_p90_PM25.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_22824\\2201075985.py:136: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0, 0, 0.9, 0.95])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: Z500_monthly_p90_PM10.png\n"
     ]
    }
   ],
   "source": [
    "# --- Helper: composite of specific dates\n",
    "def composite_dates(ds, dates):\n",
    "    dates = pd.to_datetime(dates)\n",
    "    if len(dates) == 0:\n",
    "        return None\n",
    "    # asegurar que dates están dentro del rango\n",
    "    tmin = pd.to_datetime(ds.time.min().values)\n",
    "    tmax = pd.to_datetime(ds.time.max().values)\n",
    "    dates = dates[(dates >= tmin) & (dates <= tmax)]\n",
    "    if len(dates) == 0:\n",
    "        return None\n",
    "    return ds.sel(time=ds.time.isin(dates)).mean(\"time\", skipna=True)\n",
    "\n",
    "# --- t-test: events vs non-events within the SAME month (avoid seasonality leakage)\n",
    "def ttest_mask_within_month(Hprime, event_dates, month:int):\n",
    "    event_dates = pd.to_datetime(event_dates)\n",
    "    Hm = Hprime.sel(time=Hprime.time.dt.month == month)\n",
    "\n",
    "    evt = Hm.sel(time=Hm.time.isin(event_dates))\n",
    "    ctrl = Hm.sel(time=~Hm.time.isin(event_dates))\n",
    "\n",
    "    if evt.time.size < 5 or ctrl.time.size < 5:\n",
    "        return xr.zeros_like(Hm.isel(time=0), dtype=bool)\n",
    "\n",
    "    t, p = ttest_ind(evt, ctrl, axis=0, equal_var=False, nan_policy=\"omit\")\n",
    "    return xr.DataArray(p < 0.05, coords=Hm.isel(time=0).coords)\n",
    "\n",
    "# --- Main multipanel plot: 12 months in a 3x4 layout for one pollutant\n",
    "def plot_monthly_multipanel(pol, events_by_month, Hprime, U, V, outname):\n",
    "    proj = ccrs.PlateCarree()\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(16, 9), dpi=250,\n",
    "                             subplot_kw={'projection': proj})\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    # ---- Precompute monthly anomalies to lock a consistent color scale ----\n",
    "    Hp_month = {}\n",
    "    max_abs = 0.0\n",
    "\n",
    "    for m in range(1, 13):\n",
    "        dates_m = events_by_month[m]\n",
    "        Hp = composite_dates(Hprime, dates_m)\n",
    "        Hp_month[m] = Hp\n",
    "        if Hp is not None:\n",
    "            max_abs = max(max_abs, float(np.nanmax(np.abs(Hp.values))))\n",
    "\n",
    "    if max_abs == 0:\n",
    "        raise ValueError(\"max_abs is zero. Are there no events or missing data?\")\n",
    "\n",
    "    norm = TwoSlopeNorm(vcenter=0, vmin=-max_abs, vmax=max_abs)\n",
    "    pcm_ref = None\n",
    "\n",
    "    for i, m in enumerate(range(1, 13)):\n",
    "        ax = axes[i]\n",
    "        ax.set_extent([LON_MIN, LON_MAX, LAT_MIN, LAT_MAX], crs=proj)\n",
    "\n",
    "        ax.coastlines(resolution=\"50m\", linewidth=0.5)\n",
    "        ax.add_feature(cfeature.BORDERS, linewidth=0.4)\n",
    "        ax.add_feature(cfeature.STATES.with_scale(\"50m\"), linewidth=0.3)\n",
    "\n",
    "        dates_m = events_by_month[m]\n",
    "        n_evt = len(dates_m)\n",
    "        Hp = Hp_month[m]\n",
    "\n",
    "        if Hp is None or n_evt == 0:\n",
    "            ax.set_title(f\"{calendar.month_abbr[m]} (n=0)\")\n",
    "            ax.text(0.5, 0.5, \"No events\", transform=ax.transAxes,\n",
    "                    ha=\"center\", va=\"center\", fontsize=10)\n",
    "            continue\n",
    "\n",
    "        Um = composite_dates(U, dates_m)\n",
    "        Vm = composite_dates(V, dates_m)\n",
    "\n",
    "        sig = ttest_mask_within_month(Hprime, dates_m, month=m)\n",
    "\n",
    "        Hp_np = Hp.values\n",
    "        Um_np = Um.values\n",
    "        Vm_np = Vm.values\n",
    "        sig_np = sig.values\n",
    "\n",
    "        pcm = ax.pcolormesh(lon2d, lat2d, Hp_np, cmap=\"RdBu_r\",\n",
    "                            norm=norm, shading=\"auto\", transform=proj)\n",
    "        pcm_ref = pcm\n",
    "\n",
    "        # contours\n",
    "        stepc = 5\n",
    "        lev = np.arange(-max_abs, max_abs + stepc, stepc)\n",
    "        ax.contour(lon2d, lat2d, Hp_np, levels=lev[lev > 0],\n",
    "                   colors=\"k\", linewidths=0.4, linestyles=\"solid\", transform=proj)\n",
    "        ax.contour(lon2d, lat2d, Hp_np, levels=lev[lev < 0],\n",
    "                   colors=\"k\", linewidths=0.4, linestyles=\"dashed\", transform=proj)\n",
    "\n",
    "        # vectors\n",
    "        step = 4\n",
    "        ax.quiver(lon2d[::step, ::step], lat2d[::step, ::step],\n",
    "                  Um_np[::step, ::step], Vm_np[::step, ::step],\n",
    "                  scale=700, width=0.002, color=\"black\", transform=proj)\n",
    "\n",
    "        # stippling\n",
    "        y, x = np.where(sig_np)\n",
    "        thin = 8\n",
    "        y = y[::thin]; x = x[::thin]\n",
    "        ax.scatter(lon2d[y, x], lat2d[y, x], s=2, c=\"k\", alpha=0.25, transform=proj)\n",
    "\n",
    "        # MCMA box + CDMX star\n",
    "        rect = mpatches.Rectangle((MCMA_BOX[0], MCMA_BOX[1]),\n",
    "                                  MCMA_BOX[2], MCMA_BOX[3],\n",
    "                                  fill=False, edgecolor=\"k\",\n",
    "                                  linewidth=1, transform=proj)\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        ax.plot(LON_CDMX, LAT_CDMX, marker=\"*\", color=\"gold\",\n",
    "                markersize=8, markeredgecolor=\"k\", transform=proj)\n",
    "\n",
    "        # grid labels: only left column + bottom row\n",
    "        gl = ax.gridlines(draw_labels=True, linewidth=0.2, color=\"gray\",\n",
    "                          alpha=0.5, linestyle=\"--\")\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        if (i % 4) != 0:\n",
    "            gl.left_labels = False\n",
    "        if i < 8:\n",
    "            gl.bottom_labels = False\n",
    "\n",
    "        ax.set_title(f\"{calendar.month_abbr[m]} (n={n_evt})\", fontsize=10, weight=\"bold\")\n",
    "\n",
    "    # colorbar\n",
    "    cbar_ax = fig.add_axes([0.92, 0.20, 0.015, 0.60])\n",
    "    cb = fig.colorbar(pcm_ref, cax=cbar_ax)\n",
    "    cb.set_label(\"Z500 anomaly (m)\")\n",
    "\n",
    "    fig.suptitle(f\"{pol}: Monthly Z500′ composites (p90 within month-year), 2012–2024\",\n",
    "                 fontsize=14, weight=\"bold\", y=0.98)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.9, 0.95])\n",
    "    plt.savefig(outname, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(\"Saved:\", outname)\n",
    "\n",
    "\n",
    "# --- Compute anomalies once\n",
    "Hprime500 = H500.groupby(\"time.dayofyear\") - clim500\n",
    "\n",
    "# --- Make the 12-month multipanels\n",
    "for pol in pollutants:\n",
    "    plot_monthly_multipanel(\n",
    "        pol=pol,\n",
    "        events_by_month=events_p90[pol],   # <-- dict month->dates\n",
    "        Hprime=Hprime500,\n",
    "        U=U500,\n",
    "        V=V500,\n",
    "        outname=f\"Z500_monthly_p90_{pol.replace('.', '')}.png\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd0aa4a",
   "metadata": {},
   "source": [
    "## Extra: WHO exceedance diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f520cbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WHO exceedance days for PM2.5 (thr=15.0):\n",
      "DATE\n",
      "1     327\n",
      "2     313\n",
      "3     367\n",
      "4     368\n",
      "5     361\n",
      "6     263\n",
      "7     311\n",
      "8     251\n",
      "9     237\n",
      "10    235\n",
      "11    324\n",
      "12    369\n",
      "Name: PM2.5, dtype: int64\n",
      "\n",
      "By year-month:\n",
      "DATE\n",
      "2012-01    30\n",
      "2012-02    24\n",
      "2012-03    28\n",
      "2012-04    27\n",
      "2012-05    30\n",
      "           ..\n",
      "2024-08    17\n",
      "2024-09    18\n",
      "2024-10    17\n",
      "2024-11    26\n",
      "2024-12    27\n",
      "Freq: M, Name: PM2.5, Length: 154, dtype: int64\n",
      "\n",
      "PM2.5 WHO exceedance percentage by month:\n",
      "DATE\n",
      "1    87.70\n",
      "2    88.70\n",
      "3    91.50\n",
      "4    96.60\n",
      "5    97.00\n",
      "6    73.10\n",
      "7    78.10\n",
      "8    63.40\n",
      "9    64.10\n",
      "10   62.30\n",
      "11   86.60\n",
      "12   92.20\n",
      "Name: PM2.5, dtype: float64\n",
      "\n",
      "WHO exceedance days for PM10 (thr=45.0):\n",
      "DATE\n",
      "1     277\n",
      "2     257\n",
      "3     292\n",
      "4     263\n",
      "5     215\n",
      "6      80\n",
      "7      59\n",
      "8      29\n",
      "9      30\n",
      "10     85\n",
      "11    201\n",
      "12    298\n",
      "Name: PM10, dtype: int64\n",
      "\n",
      "By year-month:\n",
      "DATE\n",
      "2012-01    26\n",
      "2012-02    15\n",
      "2012-03    27\n",
      "2012-04    25\n",
      "2012-05    28\n",
      "           ..\n",
      "2024-05    23\n",
      "2024-06     6\n",
      "2024-10     3\n",
      "2024-11     9\n",
      "2024-12    16\n",
      "Freq: M, Name: PM10, Length: 138, dtype: int64\n",
      "\n",
      "PM10 WHO exceedance percentage by month:\n",
      "DATE\n",
      "1    74.30\n",
      "2    72.80\n",
      "3    72.80\n",
      "4    69.00\n",
      "5    57.80\n",
      "6    22.20\n",
      "7    14.80\n",
      "8     7.30\n",
      "9     8.10\n",
      "10   22.50\n",
      "11   53.70\n",
      "12   74.50\n",
      "Name: PM10, dtype: float64\n",
      "\n",
      "Saved: WHO_exceedance_pct_by_month.png\n"
     ]
    }
   ],
   "source": [
    "WHO = {\"PM2.5\": 15.0, \"PM10\": 45.0}\n",
    "\n",
    "def who_exceedance_stats(df, pol, thr):\n",
    "    s = df[pol].dropna()\n",
    "    exc = s[s >= thr]\n",
    "\n",
    "    # counts aggregated over all years\n",
    "    exc_days = exc.groupby(exc.index.month).size().reindex(range(1, 13), fill_value=0)\n",
    "    total_days = s.groupby(s.index.month).size().reindex(range(1, 13), fill_value=0)\n",
    "\n",
    "    pct = (exc_days / total_days * 100).replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # by year-month (PeriodIndex)\n",
    "    counts_ym = exc.groupby(exc.index.to_period(\"M\")).size()\n",
    "\n",
    "    return exc_days, total_days, pct, counts_ym\n",
    "\n",
    "# ---------- 1) PRINT: raw outputs ----------\n",
    "results = {}  # store for plotting/table\n",
    "for pol in pollutants:\n",
    "    thr = WHO[pol]\n",
    "    exc_days, total_days, pct, counts_ym = who_exceedance_stats(df, pol, thr)\n",
    "    results[pol] = {\"exc_days\": exc_days, \"total_days\": total_days, \"pct\": pct, \"counts_ym\": counts_ym}\n",
    "\n",
    "    print(f\"\\nWHO exceedance days for {pol} (thr={thr}):\")\n",
    "    print(exc_days)\n",
    "\n",
    "    print(\"\\nBy year-month:\")\n",
    "    print(counts_ym)\n",
    "\n",
    "    print(f\"\\n{pol} WHO exceedance percentage by month:\")\n",
    "    print(pct.round(1))\n",
    "\n",
    "# ---------- 2) PLOT: % exceedance by month ----------\n",
    "months = np.arange(1, 13)\n",
    "labels = [calendar.month_abbr[m] for m in months]\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 7), dpi=200, sharex=True)\n",
    "\n",
    "bar_colors = {\"PM2.5\": \"#d55e00\", \"PM10\": \"#0072b2\"} \n",
    "\n",
    "for ax, pol in zip(axes, pollutants):\n",
    "    pct = results[pol][\"pct\"].reindex(range(1, 13))\n",
    "    ax.bar(months, pct.values, color=bar_colors.get(pol, None))\n",
    "    ax.set_title(f\"{pol}: WHO 24h exceedance percentage by month (thr={WHO[pol]} µg/m³)\")\n",
    "    ax.set_ylabel(\"% of days exceed\")\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.set_ylim(0, 100)  # percentages\n",
    "\n",
    "axes[-1].set_xticks(months)\n",
    "axes[-1].set_xticklabels(labels)\n",
    "axes[-1].set_xlabel(\"Month\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"WHO_exceedance_pct_by_month.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "print(\"\\nSaved: WHO_exceedance_pct_by_month.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02b6180c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WHO exceedance table (monthly, aggregated 2012–2024):\n",
      "   Pollutant Month  Exceed_days  Total_days  Exceed_%\n",
      "0      PM2.5   Jan          327         373     87.70\n",
      "1      PM2.5   Feb          313         353     88.70\n",
      "2      PM2.5   Mar          367         401     91.50\n",
      "3      PM2.5   Apr          368         381     96.60\n",
      "4      PM2.5   May          361         372     97.00\n",
      "5      PM2.5   Jun          263         360     73.10\n",
      "6      PM2.5   Jul          311         398     78.10\n",
      "7      PM2.5   Aug          251         396     63.40\n",
      "8      PM2.5   Sep          237         370     64.10\n",
      "9      PM2.5   Oct          235         377     62.30\n",
      "10     PM2.5   Nov          324         374     86.60\n",
      "11     PM2.5   Dec          369         400     92.20\n",
      "12      PM10   Jan          277         373     74.30\n",
      "13      PM10   Feb          257         353     72.80\n",
      "14      PM10   Mar          292         401     72.80\n",
      "15      PM10   Apr          263         381     69.00\n",
      "16      PM10   May          215         372     57.80\n",
      "17      PM10   Jun           80         360     22.20\n",
      "18      PM10   Jul           59         398     14.80\n",
      "19      PM10   Aug           29         396      7.30\n",
      "20      PM10   Sep           30         370      8.10\n",
      "21      PM10   Oct           85         377     22.50\n",
      "22      PM10   Nov          201         374     53.70\n",
      "23      PM10   Dec          298         400     74.50\n",
      "\n",
      "Saved: WHO_exceedance_table_by_month.csv\n"
     ]
    }
   ],
   "source": [
    "# ---------- 3) TABLE + CSV export ----------\n",
    "rows = []\n",
    "for pol in pollutants:\n",
    "    exc_days = results[pol][\"exc_days\"]\n",
    "    total_days = results[pol][\"total_days\"]\n",
    "    pct = results[pol][\"pct\"]\n",
    "\n",
    "    for m in range(1, 13):\n",
    "        rows.append({\n",
    "            \"Pollutant\": pol,\n",
    "            \"Month\": calendar.month_abbr[m],\n",
    "            \"Exceed_days\": int(exc_days.loc[m]),\n",
    "            \"Total_days\": int(total_days.loc[m]),\n",
    "            \"Exceed_%\": float(pct.loc[m]),\n",
    "        })\n",
    "\n",
    "who_table = pd.DataFrame(rows)\n",
    "who_table[\"Exceed_%\"] = who_table[\"Exceed_%\"].round(1)\n",
    "\n",
    "print(\"\\nWHO exceedance table (monthly, aggregated 2012–2024):\")\n",
    "print(who_table)\n",
    "\n",
    "who_table.to_csv(\"WHO_exceedance_table_by_month.csv\", index=False)\n",
    "print(\"\\nSaved: WHO_exceedance_table_by_month.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdaad5c",
   "metadata": {},
   "source": [
    "## Extra2: Exploratory hourly-based diagnostic: daily maxima vs hour of occurrence (RAMA PM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "368c070a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Settings\n",
    "# -----------------------------\n",
    "DATA_DIR = Path(\"data-icaycc\")  # folder containing the RAMA zip files\n",
    "OUT_DIR = Path(\".\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "MISSING_VALUE = -99\n",
    "\n",
    "# Years by pollutant\n",
    "YEARS_PM10 = range(1995, 2024)   # 1995–2023\n",
    "YEARS_PM25 = range(2003, 2024)   # 2003–2023\n",
    "\n",
    "# Filenames inside zip: try to match patterns like \"2023PM10.csv\" or \"2023PM25.csv\"\n",
    "POLLUTANT_TAGS = {\n",
    "    \"PM10\": [\"PM10\"],\n",
    "    \"PM25\": [\"PM25\", \"PM2.5\", \"PM2_5\"]  # be flexible\n",
    "}\n",
    "\n",
    "# Plot controls\n",
    "FIGSIZE = (16, 10)\n",
    "DPI = 300\n",
    "\n",
    "# Single 12-panel multipanel\n",
    "MONTHS_PER_FIG = None  # None -> single 3x4 multipanel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9bbb1e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Helpers: locate zip and member file\n",
    "# -----------------------------\n",
    "def zip_path_for_year(year: int) -> Path:\n",
    "    \"\"\"\n",
    "    Return path to the year RAMA zip, e.g., 95RAMA.zip for 1995, 03RAMA.zip for 2003.\n",
    "    \"\"\"\n",
    "    yy = f\"{year % 100:02d}\"\n",
    "    candidates = list(DATA_DIR.glob(f\"{yy}RAMA*.zip\"))\n",
    "    if not candidates:\n",
    "        # Try recursive search in case the zips are inside subfolders\n",
    "        candidates = list(DATA_DIR.rglob(f\"{yy}RAMA*.zip\"))\n",
    "    if not candidates:\n",
    "        raise FileNotFoundError(f\"Zip for year={year} not found. Expected something like {yy}RAMA.zip inside {DATA_DIR}\")\n",
    "    # If multiple candidates, take the shortest path (usually the direct one)\n",
    "    return sorted(candidates, key=lambda p: len(str(p)))[0]\n",
    "\n",
    "\n",
    "def find_member_for_year(zip_obj: zipfile.ZipFile, year: int, pollutant: str) -> str:\n",
    "    \"\"\"\n",
    "    Find the file inside the zip matching year and pollutant.\n",
    "    Accepts CSV or Excel-like extensions.\n",
    "    \"\"\"\n",
    "    year_str = str(year)\n",
    "    tags = POLLUTANT_TAGS[pollutant]\n",
    "\n",
    "    members = zip_obj.namelist()\n",
    "    # Prefer flat files, but allow subpaths\n",
    "    pattern_list = []\n",
    "    for tag in tags:\n",
    "        # e.g. 2023PM10.csv, 2023PM25.xls, etc.\n",
    "        pattern_list.append(re.compile(rf\".*{year_str}.*{tag}.*\\.(csv|xls|xlsx)$\", re.IGNORECASE))\n",
    "\n",
    "    matches = []\n",
    "    for m in members:\n",
    "        for pat in pattern_list:\n",
    "            if pat.match(m):\n",
    "                matches.append(m)\n",
    "\n",
    "    if not matches:\n",
    "        # If nothing matched with extensions, attempt without extension filtering\n",
    "        for tag in tags:\n",
    "            pat2 = re.compile(rf\".*{year_str}.*{tag}.*\", re.IGNORECASE)\n",
    "            for m in members:\n",
    "                if pat2.match(m):\n",
    "                    matches.append(m)\n",
    "\n",
    "    if not matches:\n",
    "        raise FileNotFoundError(f\"No member found in zip for year={year}, pollutant={pollutant}. Zip members example: {members[:10]}\")\n",
    "\n",
    "    # Prefer csv if available, else first match\n",
    "    matches_sorted = sorted(matches, key=lambda s: (0 if s.lower().endswith(\".csv\") else 1, len(s)))\n",
    "    return matches_sorted[0]\n",
    "\n",
    "\n",
    "def read_year_pollutant_from_zip(zip_path: Path, year: int, pollutant: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read one year file for a pollutant from the given zip.\n",
    "    Returns a dataframe with columns: date (datetime), hour (int), row_max (float).\n",
    "    row_max is the hourly maximum across stations for that hour.\n",
    "    \"\"\"\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "        member = find_member_for_year(z, year, pollutant)\n",
    "\n",
    "        # Read depending on extension\n",
    "        if member.lower().endswith(\".csv\"):\n",
    "            with z.open(member) as f:\n",
    "                # Try auto separator detection (tabs/commas/semicolons)\n",
    "                df = pd.read_csv(f, sep=None, engine=\"python\")\n",
    "        else:\n",
    "            with z.open(member) as f:\n",
    "                df = pd.read_excel(f)\n",
    "\n",
    "    # Standardize column names\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "\n",
    "    # Basic required cols\n",
    "    if \"FECHA\" not in df.columns or \"HORA\" not in df.columns:\n",
    "        raise ValueError(f\"Expected columns FECHA and HORA in {zip_path.name}:{member}. Found: {df.columns[:10]}\")\n",
    "\n",
    "    # Parse date (day-first)\n",
    "    df[\"FECHA\"] = pd.to_datetime(df[\"FECHA\"], dayfirst=True, errors=\"coerce\")\n",
    "\n",
    "    # Convert hour to numeric\n",
    "    df[\"HORA\"] = pd.to_numeric(df[\"HORA\"], errors=\"coerce\")\n",
    "\n",
    "    # Replace -99 with NaN\n",
    "    station_cols = [c for c in df.columns if c not in [\"FECHA\", \"HORA\"]]\n",
    "    df[station_cols] = df[station_cols].replace(MISSING_VALUE, np.nan)\n",
    "\n",
    "    # Hourly maximum across stations (regional maximum at that hour)\n",
    "    df[\"row_max\"] = df[station_cols].max(axis=1, skipna=True)\n",
    "\n",
    "    out = df[[\"FECHA\", \"HORA\", \"row_max\"]].dropna(subset=[\"FECHA\", \"HORA\"])\n",
    "    out = out.rename(columns={\"FECHA\": \"date\", \"HORA\": \"hour\"})\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17488d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Build daily maxima vs hour-of-maximum dataset\n",
    "# -----------------------------\n",
    "def build_daily_max_dataset(pollutant: str, years: range) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    For each day:\n",
    "      - finds the maximum hourly value across all stations and hours (daily maximum)\n",
    "      - stores the hour at which that maximum occurs\n",
    "    Returns DataFrame with columns: date, month, hour_of_max, daily_max\n",
    "    \"\"\"\n",
    "    daily_records = []\n",
    "\n",
    "    for y in years:\n",
    "        zpath = zip_path_for_year(y)\n",
    "        yearly = read_year_pollutant_from_zip(zpath, y, pollutant)\n",
    "\n",
    "        # Keep only valid maxima\n",
    "        yearly = yearly.dropna(subset=[\"row_max\"])\n",
    "\n",
    "        if yearly.empty:\n",
    "            continue\n",
    "\n",
    "        # For each date, locate row of the maximum row_max\n",
    "        idx = yearly.groupby(\"date\")[\"row_max\"].idxmax()\n",
    "        daily = yearly.loc[idx].copy()\n",
    "\n",
    "        daily[\"month\"] = daily[\"date\"].dt.month\n",
    "        daily = daily.rename(columns={\"hour\": \"hour_of_max\", \"row_max\": \"daily_max\"})\n",
    "\n",
    "        daily_records.append(daily[[\"date\", \"month\", \"hour_of_max\", \"daily_max\"]])\n",
    "\n",
    "    if not daily_records:\n",
    "        raise RuntimeError(f\"No daily records built for pollutant={pollutant}. Check filenames and missing values.\")\n",
    "\n",
    "    out = pd.concat(daily_records, ignore_index=True)\n",
    "    out = out.sort_values(\"date\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e2e9df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Plot: 12-month multipanel\n",
    "# -----------------------------\n",
    "def plot_dailymax_vs_hour_multipanel(\n",
    "    df_daily,\n",
    "    pollutant_label,\n",
    "    year_start,\n",
    "    year_end,\n",
    "    out_png,\n",
    "    months_per_fig=None,\n",
    "    hour_min=0,\n",
    "    hour_max=23,\n",
    "    y_max_cap=None  # numeric cap to remove extreme outliers\n",
    "):\n",
    "    \"\"\"\n",
    "    Multipanel scatter:\n",
    "      x = hour_of_max (0–23)\n",
    "      y = daily_max (units as provided)\n",
    "    Adds linear trend line, rate and R².\n",
    "    \"\"\"\n",
    "\n",
    "    # Filter invalid hours\n",
    "    df_daily = df_daily.copy()\n",
    "    df_daily = df_daily[(df_daily[\"hour_of_max\"] >= hour_min) & (df_daily[\"hour_of_max\"] <= hour_max)]\n",
    "\n",
    "    # Optional outlier cap for readability\n",
    "    if y_max_cap is not None:\n",
    "        df_daily = df_daily[df_daily[\"daily_max\"] <= y_max_cap]\n",
    "\n",
    "    months = list(range(1, 13))\n",
    "\n",
    "    # Split months if requested\n",
    "    if months_per_fig is None:\n",
    "        month_chunks = [months]\n",
    "    else:\n",
    "        month_chunks = [months[i:i+months_per_fig] for i in range(0, 12, months_per_fig)]\n",
    "\n",
    "    for chunk_i, chunk in enumerate(month_chunks, start=1):\n",
    "        n = len(chunk)\n",
    "        if n == 12:\n",
    "            nrows, ncols = 3, 4\n",
    "        elif n == 4:\n",
    "            nrows, ncols = 2, 2\n",
    "        else:\n",
    "            ncols = min(4, n)\n",
    "            nrows = int(np.ceil(n / ncols))\n",
    "\n",
    "        fig, axes = plt.subplots(nrows, ncols, figsize=FIGSIZE, dpi=DPI)\n",
    "        axes = np.array(axes).reshape(-1)\n",
    "\n",
    "        # Keep handles for a single global legend\n",
    "        sample_handle = None\n",
    "        trend_handle = None\n",
    "\n",
    "        for ax_i, m in enumerate(chunk):\n",
    "            ax = axes[ax_i]\n",
    "            sub = df_daily[df_daily[\"month\"] == m].dropna(subset=[\"hour_of_max\", \"daily_max\"]).copy()\n",
    "\n",
    "            # Scatter: open red circles\n",
    "            sc = ax.scatter(\n",
    "                sub[\"hour_of_max\"], sub[\"daily_max\"],\n",
    "                s=18, facecolors=\"none\", edgecolors=\"red\", alpha=0.55, linewidths=0.8,\n",
    "                label=\"Samples\"\n",
    "            )\n",
    "            if sample_handle is None:\n",
    "                sample_handle = sc\n",
    "\n",
    "            # Trend line\n",
    "            if len(sub) >= 2 and sub[\"hour_of_max\"].nunique() >= 2:\n",
    "                lr = linregress(sub[\"hour_of_max\"].values, sub[\"daily_max\"].values)\n",
    "                slope = lr.slope\n",
    "                r2 = (lr.rvalue ** 2) if np.isfinite(lr.rvalue) else np.nan\n",
    "\n",
    "                x_line = np.linspace(hour_min, hour_max, 100)\n",
    "                y_line = lr.intercept + slope * x_line\n",
    "\n",
    "                ln, = ax.plot(x_line, y_line, color=\"blue\", linewidth=2.0, label=\"Trend\")\n",
    "                if trend_handle is None:\n",
    "                    trend_handle = ln\n",
    "\n",
    "                # Top-right annotation in bold\n",
    "                ax.text(\n",
    "                    0.98, 0.95,\n",
    "                    f\"Rate: {slope:.2f} (µg/m³)/h\\nR²: {r2:.4f}\",\n",
    "                    transform=ax.transAxes,\n",
    "                    ha=\"right\", va=\"top\",\n",
    "                    fontsize=9,\n",
    "                    fontweight=\"bold\"\n",
    "                )\n",
    "            else:\n",
    "                ax.text(\n",
    "                    0.98, 0.95,\n",
    "                    \"Rate: n/a\\nR²: n/a\",\n",
    "                    transform=ax.transAxes,\n",
    "                    ha=\"right\", va=\"top\",\n",
    "                    fontsize=9,\n",
    "                    fontweight=\"bold\"\n",
    "                )\n",
    "\n",
    "            mon_name = calendar.month_abbr[m]\n",
    "            ax.set_title(\n",
    "                f\"Daily maxima of {pollutant_label} vs hour ({mon_name} {year_start}–{year_end})\",\n",
    "                fontsize=9,\n",
    "                fontweight=\"bold\"\n",
    "            )\n",
    "\n",
    "            ax.set_xlabel(\"Hour of daily maximum [h]\")\n",
    "            ax.set_ylabel(f\"{pollutant_label} [µg/m³]\")\n",
    "\n",
    "            # Force x ticks 0–23\n",
    "            ax.set_xlim(hour_min, hour_max)\n",
    "            ax.set_xticks(np.arange(hour_min, hour_max + 1, 2))\n",
    "\n",
    "            ax.grid(True, alpha=0.35)\n",
    "\n",
    "        # Turn off extra axes\n",
    "        for j in range(len(chunk), len(axes)):\n",
    "            axes[j].axis(\"off\")\n",
    "\n",
    "        # Global title\n",
    "        fig.suptitle(\n",
    "            f\"Maximum observed {pollutant_label}: daily maxima vs hour of occurrence\",\n",
    "            fontsize=14,\n",
    "            fontweight=\"bold\"\n",
    "        )\n",
    "\n",
    "        # Global legend (Trend / Samples only)\n",
    "        handles = []\n",
    "        labels = []\n",
    "        if trend_handle is not None:\n",
    "            handles.append(trend_handle)\n",
    "            labels.append(\"Trend\")\n",
    "        if sample_handle is not None:\n",
    "            handles.append(sample_handle)\n",
    "            labels.append(\"Samples\")\n",
    "\n",
    "        fig.legend(handles, labels, loc=\"upper left\", bbox_to_anchor=(0.01, 0.98), frameon=False)\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "        # Output name\n",
    "        if months_per_fig is None:\n",
    "            fname = out_png\n",
    "        else:\n",
    "            stem, ext = os.path.splitext(out_png)\n",
    "            fname = f\"{stem}_part{chunk_i}{ext}\"\n",
    "\n",
    "        plt.savefig(OUT_DIR / fname, dpi=DPI, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "        print(f\"Saved: {fname}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e1f8b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: PM25_dailymax_vs_hour_multipanel.png\n",
      "Saved: PM10_dailymax_vs_hour_multipanel.png\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Run for PM2.5 and PM10\n",
    "# -----------------------------\n",
    "# PM2.5 (PM25)\n",
    "df_pm25 = build_daily_max_dataset(\"PM25\", YEARS_PM25)\n",
    "plot_dailymax_vs_hour_multipanel(\n",
    "    df_pm25,\n",
    "    pollutant_label=\"PM$_{2.5}$\",\n",
    "    year_start=2003,\n",
    "    year_end=2023,\n",
    "    out_png=\"PM25_dailymax_vs_hour_multipanel.png\",\n",
    "    months_per_fig=MONTHS_PER_FIG\n",
    ")\n",
    "\n",
    "# PM10\n",
    "df_pm10 = build_daily_max_dataset(\"PM10\", YEARS_PM10)\n",
    "plot_dailymax_vs_hour_multipanel(\n",
    "    df_pm10,\n",
    "    pollutant_label=\"PM$_{10}$\",\n",
    "    year_start=1995,\n",
    "    year_end=2023,\n",
    "    out_png=\"PM10_dailymax_vs_hour_multipanel.png\",\n",
    "    months_per_fig=MONTHS_PER_FIG\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
